cv.error[i] <- cv.glm(Auto, glm.fit)$delta[1]
}
cv.error
?rep
?cv.glm
set.seed(17)
cv.error.10 <- rep(0,10)
for (i in 1:10) {
+   glm.fit <- glm(mpg ~ poly(horsepower, i), data=Auto)
+   cv.error.10[i] <- cv.glm(Auto, glm.fit, K=10)$delta[1]
+ }
cv.error.10
set.seed(17)
cv.error.10 <- rep(0,10)
for (i in 1:10) {
glm.fit <- glm(mpg ~ poly(horsepower, i), data=Auto)
cv.error.10[i] <- cv.glm(Auto, glm.fit, K=10)$delta[1]
}
cv.error.10
data(Default)
dim(Default)
head(Default)
attach(Default)
def <- glm(default ~ income + balance, data = Default, family="binomial")
summary(def)
set.seed(1)
train <- sample(10000,6000)
def2 <- glm(default ~ income + balance + student, data = Default, subset = train, family="binomial")
summary(def2)
def3 <- glm(default ~ income + balance, data = Default, subset = train, family="binomial")
summary(def3)$coefficients
summary(def3)
def3.prob <- predict(def3, Default[-train], type="response")
def3.pred <- rep(4000, "No")
def3.pred <- rep("No", 4000)
def3.pred[def3.prob > 0.5] = "Yes"
summary(def3.pred)
str(def3.pred)
length(def3.pred)
aa <- Default[-train]
dim(aa)
head(aa)
aa <- Default(!train)
aa <- Default[!train]
dim(aa)
dim(train)
aa <- Default[!train,]
dim(aa)
length(train)
head(train)
aa = Default[!train]
length(aa)
dim(aa)
rm(ls=list())
rm(ls=list())
rm(list=ls())
head(Default)
head(aa)
q()
install.packages("Shiny")
library(ISLR)
data(Default)
fit <- glm()
fit <- glm(default ~ income + balance, data=Default, family = binomial)
summary(fit)
dim(Default)
train <- sample(10000, 6000)
set.seed(1)
head(train)
length(train)
class(train)
D.train <- Default[train, ]
dim(D.train)
D.test <- Default[!train, ]
dim(D.test)
D.test <- Default[-train, ]
dim(D.test)
fit.train <- glm(default ~ income + balance, data=D.train, family=binomial)
?predict
fit.train.prob <- predict(fit.train, type="response")
head(fit.train.prob)
dim(fit.train.prob)
length(fit.train.prob)
sum(fit.train.prob > 0.5)
fit.train.pred <- rep("No", 6000)
fit.train.pred[fit.train.prob > 0.5] <- "Yes"
table(D.train$default, fit.train.pred)
(5792+61)/6000
61/(61+127)
table(fit.train.pred, D.train$default)
fit.test.prob <- predict(fit.train, D.test, type="response")
fit.test.pred <- rep("No", 4000)
fit.test.pred[fit.test.prob > 0.5] <- "Yes"
table(D.test$default, fit.test.pred)
mean(D.test$default==fit.test.pred)
(3842 + 61)/4000
(3842 + 43)/4000
train <- sample(10000,8000)
set.seed(2)
D.train <- Default[train, ]
D.test <- Default[-train, ]
fit.train <- glm(default ~ income + balance, data=D.train, family=binomial)
#do predictions on the training set
fit.train.prob <- predict(fit.train, type="response")
fit.train.pred <- rep("No", 8000)
fit.train.pred[fit.train.prob > 0.5] <- "Yes"
table(D.train$default, fit.train.pred)
mean(D.train$default == fit.train.pred)
mean(D.test$default == fit.test.pred)
train <- sample(10000,6000)
set.seed(3)
D.train <- Default[train, ]
D.test <- Default[-train, ]
fit.train.stu <- glm(default ~ income + balance + student, data=D.train, family=binomial)
#do predictions on the training set
fit.train.prob <- predict(fit.train.stu, type="response")
fit.train.pred <- rep("No", 6000)
fit.train.pred[fit.train.prob > 0.5] <- "Yes"
table(D.train$default, fit.train.pred)
mean(D.train$default == fit.train.pred)
fit.test.prob <- predict(fit.train.stu, D.test, type="response")
fit.test.pred <- rep("No", 4000)
fit.test.pred[fit.test.prob > 0.5] <- "Yes"
table(D.test$default, fit.test.pred)
mean(D.test$default == fit.test.pred)
set.seed(5)
fit.train <- glm(default ~ income + balance, data=Default, family=binomial)
summary(fit.train)
boot.fn(data,index) {
return(coef(glm(default ~ income + balance, data = Default, subset = index, family=binomial)))
}
boot.fn(data,index)
return(coef(glm(default ~ income + balance, data = Default, subset = index, family=binomial)))
boot.fn <- function(data,index) {
return(coef(glm(default ~ income + balance, data = Default, subset = index, family=binomial)))
}
boot.fn(Default, 10000)
coef(glm(default ~ income + balance, data=Default, family = binomial))
coef(glm(default ~ income + balance, data=Default, subset=10000, family = binomial))
dim(Default)
coef(glm(default ~ income + balance, data=Default, subset=1000, family = binomial))
?glm
coef(glm(default ~ income + balance, data=Default, family = binomial))
boot.fn(Default, 1:10000)
?boot
library(boot)
boot(Default, boot.fn, R=10000)
boot(Default, boot.fn, R=1000)
boot(Default, boot.fn, R=100)
summary(glm(default ~ income + balance, data=Default, family = binomial))
data(Weekly)
dim(Weekly)
head(Weekly)
dir <- glm(Direction ~ Lag1 + Lag2, data=Weekly, family=binomial)
summary(dir)
dir2 <- glm(Direction ~ Lag1 + Lag2, data=Weekly[-1,], family=binomial)
summary(dir2)
predict(dir, data=Weekly[1,], type="response")
?predict
predict(dir2, Weekly)[1]
predict(dir2, Weekly, type="response")[1]
head(Default)
predict(dir2, Weekly, type="response")[2]
pp <- predict(dir2, Weekly, type="response")
sum(pp>0,5)
length(pp)
pp <- predict(dir2, Weekly)
sum(pp > 0.5)
dim(Default)
dim(Weekly)
head(Weekly)
pp <- rep("1", 1089)
for (i in 1:1089) {
dir2 <- glm(Direction ~ Lag1 + Lag2, data=Weekly[-i,], family=binomial)
if (predict(dir2, Weekly)[i] > 0.5) {Weekly[i, 10] = "Up"}
if (Weekly[i, 10] == Weekly[i, 9]) {pp[i] = 0}
}
dim(Weekly)
pp <- rep("1", 1089)
Weekly[ ,10] <- "Down"
for (i in 1:1089) {
dir2 <- glm(Direction ~ Lag1 + Lag2, data=Weekly[-i,], family=binomial)
if (predict(dir2, Weekly)[i] > 0.5) {Weekly[i, 10] = "Up"}
if (Weekly[i, 10] == Weekly[i, 9]) {pp[i] = 0}
}
sum(pp)
head(pp)
sum(pp="1")
sum(pp=="1")
594/1089
set.seed(1)
ynorm <- rnrom(100)
y <- rnorm(100)
x <- rnorm(100)
y <- x - 2 * x^2 + rnorm(100)
plot(y,x)
dd1 <- glm(y ~ x)
summary(dd1)#coefficients
dd2 <- glm(y ~ poly(x,2))
summary(dd2)#coefficients
dd3 <- glm(y ~ poly(x,3))
summary(dd3)#coefficients
dd4 <- glm(y ~ poly(x,4))
summary(dd4)#coefficients
library(MASS)
data(Boston)
head(Boston)
mean(medv)
mean(Boston$medv)
dim(Boston)
B.mean <- mean(Boston$medv); B.mean #sample mean
B.SE <- B.mean/sqrt(nrow(Boston)); B.SEe #standard error
boot.mean <- boot(Boston$medv, mean, 150); boot.mean
boot.se <- boot.mean/sqrt(150); boot.se
B.SE <- B.mean/sqrt(nrow(Boston)); B.SE #standard error
boot.mean <- boot(Boston$medv, mean, 150); boot.mean
mean.fn <- function(data, index)
return(mean(data))
set.seed(5)
mean.fn(Boston$medv, sample(100,100, replace=T))
SE <- mean(Boston$medv)/sqrt(506)
mean.fn <- function(data, index)
return(mean(data)[index])
set.seed(5)
mean.fn(Boston$medv, sample(100,100, replace=T))
?sample
q()
library(caret)
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
head(spam)
inTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain, ]
testing <- spam[-inTrain, ]
dim(spam)
dim(training)
set.seed(32343)
modelFit <- train(type ~ ., data=training, method="glm")
modelFit <- train(type ~ ., data=training, method="glm")
install.packages("e1071")
modelFit <- train(type ~ ., data=training, method="glm")
modelFit
modelFit$finalModel
predictions <- predit(modelFit, newdata=testing)
predictions <- predict(modelFit, newdata=testing)
predictions
confusionMatrix(predictions, testing$type)
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("caret", dependencies = c("Depends", "Suggests"))
q()
install.packages("caret", dependencies = c("Depends", "Suggests"))
install.packages("caret", dependencies = c("Depends", "Suggests"))
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
library(caret)
data(AlzheimerDisease)
head(AlzheimerDisease)
dim(AlzheimerDisease)
data(AlzheimerDisease)
head(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
head(AlzheimerDisease)
data(jijijij)
q()
library(caret)
library(kernlab)
data(spam)
InTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[InTrain, ]
testing <- spam[-InTrain, ]
dim(training)
set.seed(32323)
folds <- createFolds(y=spam$type, k=10, list=TRUE, returnTrain=TRUE)
sapply(folds, length)
folds[1]
folds[[1]]
folds[[1]][1:10]
folds <- createFolds(y=spam$type, k=10, list=TRUE, returnTrain=FALSE)
folds[[1]][1:10]
?createFolds
folds <- createResample(y=spam$type, times=10, list=TRUE)
sapply(folds, length)
folds[[1]][1:10]
set.seed(32323)
tme <- 1:1000
folds <- createTimeSlices(t=tme, initialWindow=20, horizon=10)
folds <- createTimeSlices(y=tme, initialWindow=20, horizon=10)
name(folds)
names(folds)
dim(folds)
folds$train[[1]]
folds$test[[1]]
folds$train[[2]]
folds$test[[2]]
folds$train[[3]]
folds$test[[3]]
InTrain
InTrain <- createDataPartition(y=spam$type, p=0.75, list=FALSE)
training <- spam[inTrain, ]
training <- spam[InTrain, ]
testing <- spam[-InTrain, ]
modelFit <- train(type ~ ., data=training, method="glm")
args(train.default)
args(trainControl)
set.seed(1235)
modelFit2 <- train(type ~ ., data=training, method="glm")
modelFit2
library(ISLR)
data(wage)
data(Wage)
dim(Wage)
head(Wage)
summary(Wage)
InTrain <- train(y=Wage$wage, p=0.7, list=FALSE)
InTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[InTrain, ]
testing <- Wage[-Intrain, ]
testing <- Wage[-InTrain, ]
dim(training)
dim(testing)
featurePlot(x=training[c("age", "location", "jobclass")], y=training$wage, plot="pairs")
featurePlot(x=training[ ,c("age", "location", "jobclass")], y=training$wage, plot="pairs")
featurePlot(x=training[ ,c("age", "education", "jobclass")], y=training$wage, plot="pairs")
qplot(age, wage, data=training)
qplot(age, wage, data=training, color=jobclass)
qq <- qplot(age, wage, data=training, color=jobclass)
qq + geom_smooth(method="lm", formula=y~x)
qq <- qplot(age, wage, data=training, color=education)
qq + geom_smooth(method="lm", formula=y~x)
install.packages("Hmisc")
library(Hmisc)
q()
data(iris); library(caret);
table(iris$Species)
inTrain <- createDataPartition(y=iris$species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
dim(training)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain, ]
testing <- iris[-inTrain, ]
dim(training)
qplot(Sepal.Width, Petal.Width, color=Species, data=training)
qplot(Petal.Width, Sepal.Width, color=Species, data=training)
modFit <- train(Species ~ ., method="rpart", data=training)
print(modFit$finalModel)
head(training)
dim(training)
qplot(Petal.Length, Sepal.Width, color=Species, data=training)
qplot(Petal.Length, Petal.Width, color=Species, data=training)
q()
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
dim(segmenttionOriginal)
dim(segmentationOriginal)
names(segmentationOriginal)
inTrain <- train(y=Case, p=0.7, data=segmentationOriginal)
inTrain <- train(y=segmentationOriginal$Case, p=0.7, data=segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$case, p=0.7, list=FALSE)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
summary(training$Case)
head(training$Case)
head(segmentationOriginal)
modFit <- train(Case ~ ., method="rpart", data=training)
modFit <- train(Class ~ ., method="rpart", data=training)
library(rattle)
install.packages("rattle")
fancyRpartPlot(modFit)
library(rattle)
fancyRpartPlot(modFit)
summary(modFit)
fancyRpartPlot(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart")
q()
install.packages("rpart")
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=segmentationOriginal$Class, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
modFit <- train(Class ~ ., method="rpart", data=training)
fancyRpartPlot(modFit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(modFit$finalModel)
set.seed(125)
inTrain <- createDataPartition(y=segmentationOriginal$Class, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
modFit <- train(Class ~ ., method="rpart", data=training)
fancyRpartPlot(modFit$finalModel)
install.packages("pgmm")
library(pgmm)
data(olive)
dim(olive)
head(olive)
olive = olive[,-1]
fit <- train(Area ~ ., method="rpart", data=olive)
newdata = as.data.frame(t(colMeans(olive)))
pp <- predict(fit, newdata=newdata)
pp
class(olive$Area)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
dim(trainSA)
dim(testSA)
set.seed(13234)
head(training)
head(trainSA)
fit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method="glm", family="binomial", data=trainSA)
prediction <- predict(fit, newdata=trainSA, type="response")
summary(fit)
prediction <- predict(fit, type="response")
prediction <- predict(fit, newdata=testSA, type="response")
prediction <- predict(fit, testSA)
summary(prediction)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass
missClass(trainSA, prediction)
values <- trainSA[, chd]
values <- trainSA[chd]
values <- trainSA$chd
missClass(values, prediction)
prediction <- predict(fit, trainSA)
missClass(values, prediction)
prediction <- predict(fit, testSA)
values <- testSA$chd
missClass(values, prediction)
data(vowel.train)
data(vowel.test)
dim(vowel.train)
head(vowel.train)
vowel.train$y <- class(factor)
vowel.test$y <- class(factor)
class(vowel.test)
class(vowel.test$y)
summary(vowel.train$y)
class(vowel.train$y) <- "factor"
class(vowel.train$y) <- factor
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
summary(vowel.train$y)
class(vowel.train$y)
set.seed(33833)
modFit <- train(y ~ ., data = vowel.train, method = "rf", prox=TRUE)
require(randomForest)
modFit <- train(y ~ ., data = vowel.train, method = "rf", prox=TRUE)
modFit <- train(y ~ ., data = vowel.train, method = "rf")
?train
?randomForest
vowel.rf <- randomForest(y ~ ., data=vowel.train, importance=TRUE, proximity=TRUE)
summary(vowel.train$y)
head(vowel.train$y)
rm(vowel.train)
rm(vowel.test)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
head(vowel.train$y)
vowel.rf <- randomForest(y ~ ., data=vowel.train, importance=TRUE, proximity=TRUE)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
vowel.rf <- randomForest(y ~ ., data=vowel.train, importance=TRUE, proximity=TRUE)
?varimp
?varImp
varImp(vowel.rf)
varImp(vowel.rf$finalModel)
mm <- varImp(vowel.rf)
names(mm)
varImpPlot(vowel.rf, scale=TRUE)
varImp(vowel.rf)
q()
library(devtools)
install.packages("devtools")
q()
library(devtools)
install_github('slidify', 'ramnathv')
install_github('slidifyLibraries', 'ramnathv')
library(slidify)
install_github('rCharts', 'ramnathv')
q()
setwd("C:/Users/owner/Desktop/For Dell/Data Products/example/oldFaithful")
setwd("C:/Users/owner/Desktop/For Dell/Data Products/example/oldFaithful/oldFaithful")
options(rpubs.upload.method = "internal")
setwd("C:/Users/owner/Desktop/For Dell/Data Products/example/oldFaithful3")
q()
